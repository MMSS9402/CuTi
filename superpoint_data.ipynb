{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.components.superpoint import SuperPoint\n",
    "from linetr.line_detector import LSD\n",
    "from linetr.line_process import preprocess, line_tokenizer\n",
    "from linetr_utils.util_lines import find_line_matches, calculate_line_overlaps, conv_fixed_size\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "from datetime import date\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import torch.linalg\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    \"data\": {\n",
    "        \"name\": \"gcl_synth\",\n",
    "        \"image_path\": \"./assets/dataset/raw_images\",\n",
    "        \"output_path\": \"./assets/dataset/dataset_h5\",\n",
    "        \"image_type\": \"*.jpg\",\n",
    "        \"resize\": (640, 480),\n",
    "        \"visualize\": True,\n",
    "        \"n_iters\": 1,\n",
    "        \"choose_worker\": 0,\n",
    "        \"nWorkers\": 1\n",
    "    },\n",
    "    \"augmentation\": {\n",
    "        \"num\": 1,\n",
    "        \"photometric\": {\n",
    "            \"enable\": True,\n",
    "            \"primitives\": [\n",
    "                \"random_brightness\", \"random_contrast\", \"additive_speckle_noise\",\n",
    "                \"additive_gaussian_noise\", \"additive_shade\", \"motion_blur\"\n",
    "            ],\n",
    "            \"params\": {\n",
    "                \"random_brightness\": {\"max_abs_change\": 50},\n",
    "                \"random_contrast\": {\"strength_range\": [0.3, 1.5]},\n",
    "                \"additive_gaussian_noise\": {\"stddev_range\": [0, 10]},\n",
    "                \"additive_speckle_noise\": {\"prob_range\": [0, 0.0035]},\n",
    "                \"additive_shade\": {\n",
    "                    \"transparency_range\": [-0.5, 0.5],\n",
    "                    \"kernel_size_range\": [100, 150]\n",
    "                },\n",
    "                \"motion_blur\": {\"max_kernel_size\": 3}\n",
    "            }\n",
    "        },\n",
    "        \"homographic\": {\n",
    "            \"enable\": True,\n",
    "            \"params\": {\n",
    "                \"perspective\": True,\n",
    "                \"scaling\": True,\n",
    "                \"translation\": True,\n",
    "                \"rotation\": True,\n",
    "                \"patch_ratio\": 0.85,\n",
    "                \"perspective_amplitude_x\": 0.2,\n",
    "                \"perspective_amplitude_y\": 0.2,\n",
    "                \"scaling_amplitude\": 0.2,\n",
    "                \"max_angle\": 1.0472,\n",
    "                \"allow_artifacts\": True\n",
    "            },\n",
    "            \"valid_border_margin\": 3\n",
    "        }\n",
    "    },\n",
    "    \"feature\": {\n",
    "        \"linetr\": {\n",
    "            \"min_length\": 16,\n",
    "            \"token_distance\": 8,\n",
    "            \"max_tokens\": 21,\n",
    "            \"remove_borders\": 1,\n",
    "            \"max_sublines\": 250,\n",
    "            \"thred_reprojected\": 3,\n",
    "            \"thred_angdiff\": 2,\n",
    "            \"min_overlap_ratio\": 0.3\n",
    "        },\n",
    "        \"superpoint\": {\n",
    "            \"nms_radius\": 4,\n",
    "            \"keypoint_threshold\": 0.005,\n",
    "            \"remove_borders\": 4,\n",
    "            \"max_keypoints\": 256\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = SuperPoint(conf['feature']['superpoint']).to(device).eval()\n",
    "linedetector = LSD(conf['feature']['linetr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kmuvcl/source/oldCuTi/CuTi/matterport/mp3d_planercnn_json/cached_set_moon_val_vp.json\"\n",
    "root = \"/home/kmuvcl/source/oldCuTi/CuTi/matterport/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as file:\n",
    "    split = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['data']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(split['data']))):\n",
    "    del split['data'][str(i)]['gt_corrs']\n",
    "    del split['data'][str(i)]['0']['annotations']\n",
    "    del split['data'][str(i)]['1']['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "lines_list = []\n",
    "vps_list = []\n",
    "poses_list = []\n",
    "intrinsics_list = []\n",
    "\n",
    "original_basepath = \"/Pool1/users/jinlinyi/dataset/mp3d_rpnet_v4_sep20\"\n",
    "data_path = \"/home/kmuvcl/source/oldCuTi/CuTi/matterport\"\n",
    "\n",
    "resize = (640,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, device, resize):\n",
    "    image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if resize[0] != -1:\n",
    "        image = cv2.resize(image.astype('float32'), (resize[0], resize[1]))\n",
    "        gray = cv2.resize(gray.astype('uint8'), (resize[0], resize[1]))\n",
    "    gray_torch = torch.from_numpy(gray/255.).float()[None, None].to(device)\n",
    "    \n",
    "    return image, gray, gray_torch\n",
    "\n",
    "def read_line_file(filename: str, min_line_length=10):\n",
    "        segs = []  # line segments\n",
    "\n",
    "        with open(filename, \"r\") as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            for row in csvreader:\n",
    "                segs.append([float(row[0]), float(row[1]), float(row[2]), float(row[3])])\n",
    "        segs = np.array(segs, dtype=np.float32)\n",
    "        lengths = LA.norm(segs[:, 2:] - segs[:, :2], axis=1)\n",
    "        segs = segs[lengths > min_line_length]\n",
    "        return segs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klines_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['data'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(tqdm(split[\"data\"].values())):\n",
    "    vps = []\n",
    "    images_list = []\n",
    "    \n",
    "    for img_idx in [\"0\", \"1\"]:\n",
    "        img_path = data[img_idx][\"file_name\"].replace(original_basepath, data_path)\n",
    "        images_list.append(img_path)\n",
    "    images = []\n",
    "    grays = []\n",
    "    for j in range(2):\n",
    "        images.append(cv2.imread(images_list[j], cv2.IMREAD_COLOR))\n",
    "        \n",
    "    images[0] = cv2.resize(images[0].astype('float32'), (480,640))\n",
    "    images[1] = cv2.resize(images[1].astype('float32'), (480,640))\n",
    "    grays.append(cv2.cvtColor(images[0], cv2.COLOR_RGB2GRAY))\n",
    "    grays.append(cv2.cvtColor(images[1], cv2.COLOR_RGB2GRAY))\n",
    "    \n",
    "    grays[0] = cv2.resize(grays[0].astype('uint8'), (resize[0], resize[1]))\n",
    "    grays[1] = cv2.resize(grays[1].astype('uint8'), (resize[0], resize[1]))\n",
    "    \n",
    "    image0_torch = torch.from_numpy(grays[0]/255.).float()[None, None].to(device)\n",
    "    image1_torch = torch.from_numpy(grays[1]/255.).float()[None, None].to(device)\n",
    "    \n",
    "    height, width = image_shape = grays[0].shape\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred0 = model({'image': image0_torch})\n",
    "        pred1 = model({'image': image1_torch})\n",
    "        \n",
    "    valid_mask0 = np.ones_like(grays[0])\n",
    "    valid_mask1 = np.ones_like(grays[1])  \n",
    "    \n",
    "    klns0_cv = linedetector.detect(grays[0])\n",
    "    klns1_cv = linedetector.detect(grays[1])\n",
    "    \n",
    "    try:\n",
    "        klines0 = preprocess(klns0_cv, image_shape, pred0, mask=valid_mask0, conf=conf['feature']['linetr'])   ## TODO: torch vs. np. 잘 정리하기, tokenizer 다시 정리\n",
    "        klines1 = preprocess(klns1_cv, image_shape, pred1, mask=valid_mask1, conf=conf['feature']['linetr'])\n",
    "    except:\n",
    "        print(\"line preprocess break\")\n",
    "        break\n",
    "    klines0 = conv_fixed_size(klines0, conf, func_token=line_tokenizer, pred_sp=pred0)\n",
    "    klines1 = conv_fixed_size(klines1, conf, func_token=line_tokenizer, pred_sp=pred1)\n",
    "    \n",
    "    klns0 = klines0['sublines'].reshape(-1, 2, 2).cpu().numpy()\n",
    "    klns1 = klines1['sublines'].reshape(-1, 2, 2).cpu().numpy()\n",
    "    \n",
    "    keys_l = ['klines', 'sublines', 'angle_sublines','pnt_sublines', 'desc_sublines', \\\n",
    "            'score_sublines', 'resp_sublines', 'mask_sublines', 'num_klns', 'mat_klines2sublines', 'num_slns']\n",
    "        # klines, resp, angle, pnt, desc, score, mask\n",
    "    klines0 = {k:v[0] for k,v in klines0.items() if k in keys_l}\n",
    "    klines1 = {k:v[0] for k,v in klines1.items() if k in keys_l}\n",
    "\n",
    "    data['0']['klines'] = klines0\n",
    "    data['1']['klines'] = klines1\n",
    "\n",
    "    if i ==7:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klines_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['data']['0']['1']['klines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cached_set_sp_moon_val_vp.json', 'w') as f : \n",
    "\tjson.dump(split, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(klns0_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klines0.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klines0['num_slns0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5py_to_dict(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        return {key: torch.tensor(f[key][:]) for key in f.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = load_h5py_to_dict('/home/kmuvcl/source/oldCuTi/CuTi/matterport/rgb/2t7WUuJeko7/0_2_11_sp_line.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['sublines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['mask_sublines'][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['sublines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['klines'][0,247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines = dict['sublines'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict['desc_sublines'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_safe_np(v, axis=-1, eps=1e-6):\n",
    "    de = LA.norm(v, axis=axis, keepdims=True)\n",
    "    de = np.maximum(de, eps)\n",
    "    return v / de\n",
    "\n",
    "def segs2lines_np(segs):\n",
    "    ones = np.ones(len(segs))\n",
    "    ones = np.expand_dims(ones, axis=-1)\n",
    "    p1 = np.concatenate([segs[:, :2], ones], axis=-1)\n",
    "    p2 = np.concatenate([segs[:, 2:], ones], axis=-1)\n",
    "    lines = np.cross(p1, p2)\n",
    "    return normalize_safe_np(lines)\n",
    "\n",
    "def normalize_segs(self, lines, pp, rho=517.97):\n",
    "    pp = np.array([pp[0], pp[1], pp[0], pp[1]], dtype=np.float32)\n",
    "    return (lines - pp)/rho\n",
    "\n",
    "def sample_segs_np(segs, num_sample):\n",
    "    num_segs = len(segs)\n",
    "    sampled_segs = np.zeros([num_sample, 4], dtype=np.float32)\n",
    "    mask = np.zeros([num_sample, 1], dtype=np.float32)\n",
    "    if num_sample > num_segs:\n",
    "        sampled_segs[:num_segs] = segs\n",
    "        mask[:num_segs] = np.ones([num_segs, 1], dtype=np.float32)\n",
    "    else:\n",
    "        lengths = LA.norm(segs[:, 2:] - segs[:, :2], axis=-1)\n",
    "        prob = lengths / np.sum(lengths)\n",
    "        idxs = np.random.choice(segs.shape[0], num_sample, replace=True, p=prob)\n",
    "        sampled_segs = segs[idxs]\n",
    "        mask = np.ones([num_sample, 1], dtype=np.float32)\n",
    "    return sampled_segs, mask\n",
    "\n",
    "def coordinate_yup(segs, org_h):\n",
    "    H = np.array([0, org_h, 0, org_h])\n",
    "    segs[:, 1] = -segs[:, 1]\n",
    "    segs[:, 3] = -segs[:, 3]\n",
    "    return (H + segs)\n",
    "\n",
    "def get_line_dist(line):\n",
    "    sp = line[0]\n",
    "    ep = line[1]\n",
    "    return np.sqrt(np.sum((ep-sp)**2))\n",
    "\n",
    "def point_on_line(line, dist_px):\n",
    "    assert dist_px >= 0, 'distance should be positive!'\n",
    "    assert get_line_dist(line) >= dist_px, 'distance should be smaller than line length!'\n",
    "\n",
    "    sp,ep = line\n",
    "    vec = ep - sp\n",
    "    if vec[0] != 0:\n",
    "        m = vec[1]/vec[0]\n",
    "        x = np.sqrt(dist_px**2/(1+m**2))\n",
    "        y = m*x\n",
    "    else:\n",
    "        x = 0\n",
    "        y = dist_px if ep[1]-sp[1] > 0 else -dist_px\n",
    "\n",
    "    return (x,y)+sp\n",
    "\n",
    "def sample_descriptors(keypoints, descriptors, s: int = 8):\n",
    "    \"\"\" Interpolate descriptors at keypoint locations \"\"\"\n",
    "    b, c, h, w = descriptors.shape\n",
    "    keypoints = keypoints - s / 2 + 0.5\n",
    "    keypoints /= torch.tensor([(w*s - s/2 - 0.5), (h*s - s/2 - 0.5)],\n",
    "                              ).to(keypoints)[None]\n",
    "    keypoints = keypoints*2 - 1  # normalize to (-1, 1)\n",
    "    args = {'align_corners': True} if int(torch.__version__[2]) > 2 else {}\n",
    "    descriptors = torch.nn.functional.grid_sample(\n",
    "        descriptors, keypoints.view(b, 1, -1, 2), mode='bilinear', **args)\n",
    "    descriptors = torch.nn.functional.normalize(\n",
    "        descriptors.reshape(b, c, -1), p=2, dim=1)\n",
    "    return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines = sublines.reshape(250,-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines = coordinate_yup(sublines,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "token_distance = 8\n",
    "width = 640\n",
    "height = 480\n",
    "max_tokens = 21\n",
    "slines_all, num_slines_all = [], []\n",
    "tokens_all, masks_all = [], []\n",
    "response_all, angle_all = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kline = dict['klines']\n",
    "klength = dict['length_klines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kline[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = int(math.ceil(klength[0][0] / 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (kline, klength) in enumerate(zip(dict['klines'][0].numpy(), dict['length_klines'][0].numpy())):\n",
    "    print(kline)\n",
    "    tokens = []\n",
    "    num_tokens = int(math.ceil(klength / token_distance))\n",
    "    print(num_tokens)\n",
    "    for i_token in range(num_tokens-1):\n",
    "        dist = i_token * token_distance\n",
    "        token = point_on_line(kline, dist)\n",
    "        tokens.append(token)\n",
    "    token = kline[1]\n",
    "    token[0]=token[0].clip(max=width-0.6)\n",
    "    token[1]=token[1].clip(max=height-0.6)\n",
    "    tokens.append(token)\n",
    "    sp,ep = kline\n",
    "    num_sublines = int(math.ceil(num_tokens / max_tokens))\n",
    "    sublines = np.zeros((num_sublines,2,2))\n",
    "    sublines[0,0] = sp\n",
    "    sublines[-1,1] = ep\n",
    "    for i_sline in range(num_sublines-1):\n",
    "        mid_token = tokens[(i_sline+1)*max_tokens-1]\n",
    "        sublines[i_sline, 1] = mid_token\n",
    "        sublines[i_sline+1, 0] = mid_token\n",
    "    slines_all.extend(sublines)\n",
    "    num_slines_all.append(num_sublines)\n",
    "\n",
    "    # line tokens & masks for sublines\n",
    "    tokens_sline = np.zeros((num_sublines,max_tokens,2))\n",
    "    masks_sline = np.zeros((num_sublines,max_tokens+1,1))\n",
    "    masks_sline[:,0] = 1\n",
    "\n",
    "    for i_sline in range(num_sublines):\n",
    "        i_start = i_sline*max_tokens\n",
    "        i_end = i_start + max_tokens\n",
    "        tmp_tokens = np.asarray(tokens[i_start:i_end])\n",
    "        tokens_sline[i_sline,:len(tmp_tokens)] = tmp_tokens\n",
    "        masks_sline[i_sline,1:len(tmp_tokens)+1] = 1\n",
    "    tokens_all.extend(tokens_sline)\n",
    "    masks_all.extend(masks_sline)\n",
    "\n",
    "    resp_sline = np.zeros((num_sublines,1))\n",
    "    ang_sline = np.zeros((num_sublines,2))\n",
    "    max_length = token_distance * max_tokens\n",
    "    for i_sline in range(num_sublines):\n",
    "        resp_sline[i_sline] = get_line_dist(sublines[i_sline]) / max_length\n",
    "        ang_sline[i_sline] = dict['angles'][0][i]\n",
    "    response_all.extend(resp_sline)\n",
    "    angle_all.extend(ang_sline)\n",
    "    \n",
    "    device = 'cpu'\n",
    "    # device = 'cpu'\n",
    "    slines = torch.from_numpy(np.vstack(slines_all).reshape(-1,2,2)).float().to(device)\n",
    "    tokens = torch.from_numpy(np.vstack(tokens_all).reshape(-1,max_tokens,2)).float().to(device)\n",
    "    masks = torch.from_numpy(np.vstack(masks_all).reshape(-1,max_tokens+1,1)).float().to(device)\n",
    "    responses = torch.from_numpy(np.vstack(response_all).reshape(-1,1)).float().to(device)\n",
    "    angles = torch.from_numpy(np.vstack(angle_all).reshape(-1,2)).float().to(device)\n",
    "    \n",
    "    # adjacency matrix (mat_keylines2sublines)\n",
    "    klines2slines = torch.zeros((len(dict['klines'][0]), len(slines))).to(device)\n",
    "    st_idx = 0\n",
    "    for i, num_sline in enumerate(num_slines_all):\n",
    "        klines2slines[i,st_idx:st_idx+num_sline] = 1/num_sline\n",
    "        st_idx += num_sline\n",
    "\n",
    "    # descriptors & scores for line tokens\n",
    "    dense_descriptor = dict['dense_descriptor'][0]\n",
    "    descriptors = sample_descriptors(tokens[None], dense_descriptor, 8)[0].reshape(256,tokens.shape[0],tokens.shape[1])\n",
    "    descriptors = descriptors.permute(1,2,0)\n",
    "\n",
    "    dense_score = dict['dense_score'].transpose(1,2)\n",
    "    pos_score = [torch.round(tokens).long().reshape(-1,2)]\n",
    "    pos_score[0][:,0] = pos_score[0][:,0].clip(max=dense_score.shape[1]-1)\n",
    "    pos_score[0][:,1] = pos_score[0][:,1].clip(max=dense_score.shape[2]-1)\n",
    "    scores = [s[tuple(k.t())] for s, k in zip(dense_score, pos_score)]\n",
    "    scores = scores[0].reshape(len(slines), max_tokens, 1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slines[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = torch.tensor([[ 8.8663e-01, -8.8244e-02,  4.5397e-01],\n",
    "         [ 0.0000e+00,  9.8163e-01,  1.9081e-01],\n",
    "         [-4.6247e-01, -1.6918e-01,  8.7034e-01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = vp.transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(vp[0],vp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/home/kmuvcl/source/CuTi/intrinsics.npz\") as npz:\n",
    "    np = npz\n",
    "    scene0000_00 = np['scene0000_00']\n",
    "    scene0001_00 = np['scene0001_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([577.5907 ,   0.     , 318.90543,   0.     , 578.7298 , 242.68361,\n",
       "         0.     ,   0.     ,   1.     ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene0000_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scene0000_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kmuvcl/source/CuTi/superpoint_data.ipynb Cell 54\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.246.112.110/home/kmuvcl/source/CuTi/superpoint_data.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m scene0000_01\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scene0000_01' is not defined"
     ]
    }
   ],
   "source": [
    "scene0000_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([577.8706,   0.    , 319.5   ,   0.    , 577.8706, 239.5   ,\n",
       "         0.    ,   0.    ,   1.    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene0001_00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/kmuvcl/source/CuTi/superpoint_data.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B203.246.112.110/home/kmuvcl/source/CuTi/superpoint_data.ipynb#Y110sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m scene0000_00 \u001b[39m=\u001b[39m np[\u001b[39m'\u001b[39;49m\u001b[39mscene0000_00\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/numpy/lib/npyio.py:248\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    246\u001b[0m     key \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m member:\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mbytes\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mzip\u001b[39m.\u001b[39;49mopen(key)\n\u001b[1;32m    249\u001b[0m     magic \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m(\u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mMAGIC_PREFIX))\n\u001b[1;32m    250\u001b[0m     \u001b[39mbytes\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'open'"
     ]
    }
   ],
   "source": [
    "scene0000_00 = np['scene0000_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene0706_00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[1512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(\"/home/kmuvcl/dataset/data/scannet-vp/scene0000_00/frame-000000-vanish.npz\") as npz:\n",
    "        vpts = np.array([npz[d] for d in [\"x\", \"y\", \"z\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.94929364e-01, -2.46233042e-01,  5.54487317e-01],\n",
       "       [-6.06701116e-01, -3.23240044e-01,  7.26242608e-01],\n",
       "       [-4.07651387e-04,  9.13720846e-01,  4.06343490e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/home/kmuvcl/dataset/data/scannet-vp/scene0000_00/frame-000000-color.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuti",
   "language": "python",
   "name": "cuti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
