{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/.conda/envs/cuti2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import csv\n",
    "import numpy.linalg as LA\n",
    "import data.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eul2rotm_ypr(euler):\n",
    "    R_x = np.array(\n",
    "        [\n",
    "            [1, 0, 0],\n",
    "            [0, np.cos(euler[0]), -np.sin(euler[0])],\n",
    "            [0, np.sin(euler[0]), np.cos(euler[0])],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    R_y = np.array(\n",
    "        [\n",
    "            [np.cos(euler[1]), 0, np.sin(euler[1])],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(euler[1]), 0, np.cos(euler[1])],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    R_z = np.array(\n",
    "        [\n",
    "            [np.cos(euler[2]), -np.sin(euler[2]), 0],\n",
    "            [np.sin(euler[2]), np.cos(euler[2]), 0],\n",
    "            [0, 0, 1],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    return np.dot(R_z, np.dot(R_x, R_y))\n",
    "\n",
    "\n",
    "def create_masks(image):\n",
    "    masks = torch.zeros((1, height, width), dtype=torch.uint8)\n",
    "    return masks\n",
    "\n",
    "\n",
    "def read_line_file(filename, min_line_length=10):\n",
    "    segs = []  # line segments\n",
    "    # csv 파일 열어서 Line 정보 가져오기\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            segs.append([float(row[0]), float(row[1]), float(row[2]), float(row[3])])\n",
    "    segs = np.array(segs, dtype=np.float32)\n",
    "    lengths = LA.norm(segs[:, 2:] - segs[:, :2], axis=1)\n",
    "    segs = segs[lengths > min_line_length]\n",
    "    return segs\n",
    "\n",
    "\n",
    "def normalize_segs(segs, pp, rho):\n",
    "    pp = np.array([pp[0], pp[1], pp[0], pp[1]], dtype=np.float32)\n",
    "    return rho * (segs - pp)\n",
    "\n",
    "\n",
    "def normalize_safe_np(v, axis=-1, eps=1e-6):\n",
    "    de = LA.norm(v, axis=axis, keepdims=True)\n",
    "    de = np.maximum(de, eps)\n",
    "    return v / de\n",
    "\n",
    "\n",
    "def segs2lines_np(segs):\n",
    "    ones = np.ones(len(segs))\n",
    "    ones = np.expand_dims(ones, axis=-1)\n",
    "    p1 = np.concatenate([segs[:, :2], ones], axis=-1)\n",
    "    p2 = np.concatenate([segs[:, 2:], ones], axis=-1)\n",
    "    lines = np.cross(p1, p2)\n",
    "    return normalize_safe_np(lines)\n",
    "\n",
    "\n",
    "def sample_segs_np(segs, num_sample, use_prob=True):\n",
    "    num_segs = len(segs)\n",
    "    sampled_segs = np.zeros([num_sample, 4], dtype=np.float32)\n",
    "    mask = np.zeros([num_sample, 1], dtype=np.float32)\n",
    "    if num_sample > num_segs:\n",
    "        sampled_segs[:num_segs] = segs\n",
    "        mask[:num_segs] = np.ones([num_segs, 1], dtype=np.float32)\n",
    "    else:\n",
    "        lengths = LA.norm(segs[:, 2:] - segs[:, :2], axis=-1)\n",
    "        prob = lengths / np.sum(lengths)\n",
    "        idxs = np.random.choice(segs.shape[0], num_sample, replace=True, p=prob)\n",
    "        sampled_segs = segs[idxs]\n",
    "        mask = np.ones([num_sample, 1], dtype=np.float32)\n",
    "    return sampled_segs, mask\n",
    "\n",
    "\n",
    "def sample_vert_segs_np(segs, thresh_theta=22.5):\n",
    "    lines = segs2lines_np(segs)\n",
    "    (a, b) = lines[:, 0], lines[:, 1]\n",
    "    theta = np.arctan2(np.abs(b), np.abs(a))\n",
    "    thresh_theta = np.radians(thresh_theta)\n",
    "    return segs[theta < thresh_theta]\n",
    "def make_transform(self):\n",
    "    return T.Compose(\n",
    "        [T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/moon/source/CuTi/matterport/mp3d_planercnn_json/cached_set_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/moon/source/CuTi/matterport/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(path)) as f:\n",
    "   split = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rgb', '17DRP5sb8fy', '0_0_10.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(split['data'][0]['0']['file_name']).split('/')[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_info = {\n",
    "            \"images\": [],\n",
    "            \"poses\": [],\n",
    "            \"intrinsics\": [],\n",
    "            \"lines\": [],\n",
    "        }  # line 정보 추가\n",
    "base_pose = np.array([0, 0, 0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filename = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {}\n",
    "extra = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    images = []\n",
    "    lines = []\n",
    "    for imgnum in [\"0\", \"1\"]:\n",
    "        img_name = os.path.join(\n",
    "            root,\n",
    "            \"/\".join(str(split[\"data\"][i][imgnum][\"file_name\"]).split(\"/\")[6:]),\n",
    "        )\n",
    "        line_name = img_name.split(\"/\")\n",
    "        line_name[8] = img_name.split(\"/\")[8].split(\".\")[0] + \"_line.csv\"\n",
    "        line_name = \"/\".join(line_name)\n",
    "\n",
    "        images.append(img_name)\n",
    "        lines.append(line_name)\n",
    "\n",
    "    rel_pose = np.array(\n",
    "        split[\"data\"][i][\"rel_pose\"][\"position\"]\n",
    "        + split[\"data\"][i][\"rel_pose\"][\"rotation\"]\n",
    "    )\n",
    "    og_rel_pose = np.copy(rel_pose)\n",
    "\n",
    "    # on matterport, we scale depths to balance rot & trans loss\n",
    "    rel_pose[:3] /= 0.5\n",
    "    cprp = np.copy(rel_pose)\n",
    "    rel_pose[6] = cprp[\n",
    "        3\n",
    "    ]  # swap 3 & 6, we want W last for consistency with our other datasets\n",
    "    rel_pose[3] = cprp[6]\n",
    "    if rel_pose[6] < 0:  # normalize quaternions to have positive \"W\"\n",
    "        rel_pose[3:] *= -1\n",
    "    poses = np.vstack([base_pose, rel_pose])\n",
    "\n",
    "    intrinsics = np.array(\n",
    "        [[517.97, 517.97, 320, 240], [517.97, 517.97, 320, 240]]\n",
    "    )  # 480 x 640 imgs\n",
    "\n",
    "    scene_info[\"images\"].append(images)\n",
    "    scene_info[\"poses\"] += [poses]\n",
    "    scene_info[\"intrinsics\"] += [intrinsics]\n",
    "    scene_info[\"lines\"].append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = scene_info[\"poses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00],\n",
       "       [ 3.11850524e+00,  1.98698733e-01, -9.10757182e-01,\n",
       "         5.83339888e-02,  1.73472348e-17,  3.00102356e-01,\n",
       "         9.52121695e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = np.stack(poses).astype(np.float32)\n",
    "poses = torch.from_numpy(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lietorch\n",
    "from lietorch import SE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_preds(self, Gs, pose_preds):\n",
    "        pred_out_Gs = SE3(pose_preds)\n",
    "        \n",
    "        normalized = pred_out_Gs.data[:,:,3:].norm(dim=-1).unsqueeze(2)\n",
    "        eps = torch.ones_like(normalized) * .01\n",
    "        pred_out_Gs_new = SE3(torch.clone(pred_out_Gs.data))\n",
    "        pred_out_Gs_new.data[:,:,3:] = pred_out_Gs.data[:,:,3:] / torch.max(normalized, eps)\n",
    "        \n",
    "        # print(\"shape____1\",Gs[:,:1].data.shape)\n",
    "        # print(\"shape____2\",pred_out_Gs_new.data[:,1:].shape)\n",
    "        \n",
    "        these_out_Gs = SE3(torch.cat([Gs[:,:1].data, pred_out_Gs_new.data[:,1:]], dim=1))\n",
    "            \n",
    "        # if inference:\n",
    "        #     out_Gs = these_out_Gs.data[0].cpu().numpy()\n",
    "        # else:\n",
    "        out_Gs = [these_out_Gs]\n",
    "\n",
    "        return out_Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ps = SE3(poses)\n",
    "Gs = SE3.IdentityLike(Ps)\n",
    "Ps_out = SE3(Ps.data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ps_out == Ps\n",
    "#Ps_est == Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii, jj = torch.tensor([0, 1]), torch.tensor([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SE3: size=torch.Size([2]), device=cpu, dtype=torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_out[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SE3: size=torch.Size([2]), device=cpu, dtype=torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_out[:,ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SE3: size=torch.Size([2]), device=cpu, dtype=torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps_out2 = Ps_out[:,ii].inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dP = Ps_out[:,jj] * Ps_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dP = torch.from_numpy(dP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dP.inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('cuti2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e1a44bf8a61e1de9a6f181aa40111e7a6892ae5d6d12f0851df0a95b2d5da0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
