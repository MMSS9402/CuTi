{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from test_data.factory_test import dataset_factory\n",
    "from config import cfg\n",
    "\n",
    "import lietorch\n",
    "from lietorch import SE3\n",
    "from geom.losses import geodesic_loss\n",
    "# from src.geom.losses import geodesic_loss\n",
    "\n",
    "# network\n",
    "# from src.model import ViTEss\n",
    "from logger import Logger\n",
    "from cuti import build\n",
    "\n",
    "# DDP training\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from cuti import build\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Matterport dataset\n",
      "Dataset matterport has 7996 images\n"
     ]
    }
   ],
   "source": [
    "db = dataset_factory(\n",
    "    [\"matterport\"],\n",
    "    datapath=\"/home/kmuvcl/source/CuTi/matterport\",\n",
    "    subepoch=0,\n",
    "    is_training=False,\n",
    "    gpu = 0,\n",
    "    streetlearn_interiornet_type = None,\n",
    "    use_mini_dataset = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = \"/home/kmuvcl/source/CuTi/checkpoint/120000.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = OrderedDict([\n",
    "        (k.replace(\"module.\", \"\"), v) for (k, v) in torch.load(ckpt)['model'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict,False)\n",
    "model = model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(\n",
    " db, batch_size=cfg.SOLVER.BATCH_SIZE, num_workers=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH_SCALE =5\n",
    "predictions = {'camera': {'preds': {'tran': [], 'rot': []}, 'gts': {'tran': [], 'rot': []}}}\n",
    "loss_list =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_camera(predictions):\n",
    "    acc_threshold = {\n",
    "        \"tran\": 1.0,\n",
    "        \"rot\": 30,\n",
    "    }  # threshold for translation and rotation error to say prediction is correct.\n",
    "\n",
    "    pred_tran = np.vstack(predictions[\"camera\"][\"preds\"][\"tran\"])\n",
    "    pred_rot = np.vstack(predictions[\"camera\"][\"preds\"][\"rot\"])\n",
    "\n",
    "    gt_tran = np.vstack(predictions[\"camera\"][\"gts\"][\"tran\"])\n",
    "    gt_rot = np.vstack(predictions[\"camera\"][\"gts\"][\"rot\"])\n",
    "\n",
    "    top1_error = {\n",
    "        \"tran\": np.linalg.norm(gt_tran - pred_tran, axis=1),\n",
    "        \"rot\": 2 * np.arccos(np.clip(np.abs(np.sum(np.multiply(pred_rot, gt_rot), axis=1)), -1.0, 1.0)) * 180 / np.pi,\n",
    "    }\n",
    "    top1_accuracy = {\n",
    "        \"tran\": (top1_error[\"tran\"] < acc_threshold[\"tran\"]).sum()\n",
    "        / len(top1_error[\"tran\"]),\n",
    "        \"rot\": (top1_error[\"rot\"] < acc_threshold[\"rot\"]).sum()\n",
    "        / len(top1_error[\"rot\"]),\n",
    "    }\n",
    "    camera_metrics = {\n",
    "        f\"top1 T err < {acc_threshold['tran']}\": top1_accuracy[\"tran\"] * 100,\n",
    "        f\"top1 R err < {acc_threshold['rot']}\": top1_accuracy[\"rot\"] * 100,\n",
    "        f\"T mean err\": np.mean(top1_error[\"tran\"]),\n",
    "        f\"R mean err\": np.mean(top1_error[\"rot\"]),\n",
    "        f\"T median err\": np.median(top1_error[\"tran\"]),\n",
    "        f\"R median err\": np.median(top1_error[\"rot\"]),\n",
    "    }\n",
    "    \n",
    "    gt_mags = {\"tran\": np.linalg.norm(gt_tran, axis=1), \"rot\": 2 * np.arccos(gt_rot[:,0]) * 180 / np.pi}\n",
    "\n",
    "    tran_graph = np.stack([gt_mags['tran'], top1_error['tran']],axis=1)\n",
    "    tran_graph_name = os.path.join('output', args.exp, output_folder, 'gt_translation_magnitude_vs_error.csv')\n",
    "    np.savetxt(tran_graph_name, tran_graph, delimiter=',', fmt='%1.5f')\n",
    "\n",
    "    rot_graph = np.stack([gt_mags['rot'], top1_error['rot']],axis=1)\n",
    "    rot_graph_name = os.path.join('output', args.exp, output_folder, 'gt_rotation_magnitude_vs_error.csv')\n",
    "    np.savetxt(rot_graph_name, rot_graph, delimiter=',', fmt='%1.5f')\n",
    "    \n",
    "    return camera_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 400/1333 [03:06<07:36,  2.04batch/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0489070dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0489070dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/kmuvcl/anaconda3/envs/cuti/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "100%|█████████▉| 1332/1333 [10:08<00:00,  2.19batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m Ps_out \u001b[38;5;241m=\u001b[39m SE3(Ps\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     poses_est \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#print(poses.shape)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#print(poses[0][1])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/source/CuTi/cuti.py:113\u001b[0m, in \u001b[0;36mCuTi.forward\u001b[0;34m(self, images, lines, Gs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m(output\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size):\n\u001b[1;32m    112\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer3(output)\n\u001b[1;32m    114\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[39m#output = output.squeeze() \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/nn/modules/linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "    for i_batch, item in enumerate(tepoch):\n",
    "        images, poses, intrinsics, lines = [x.to(\"cuda\") for x in item]\n",
    "        Ps = SE3(poses) \n",
    "        Gs = SE3.IdentityLike(Ps)\n",
    "        Ps_out = SE3(Ps.data.clone())\n",
    "        with torch.no_grad():\n",
    "            poses_est = model(images, lines, Gs)\n",
    "        #print(poses.shape)\n",
    "        #print(poses[0][1])\n",
    "        for i in range(6):\n",
    "            predictions['camera']['gts']['tran'].append(poses[i][1][:3])\n",
    "            gt_rotation = poses[i][1][3:]\n",
    "            if gt_rotation[0] < 0: # normalize quaternions to have positive \"W\" (equivalent)\n",
    "                gt_rotation[0] *= -1\n",
    "                gt_rotation[1] *= -1\n",
    "                gt_rotation[2] *= -1\n",
    "                gt_rotation[3] *= -1\n",
    "            predictions['camera']['gts']['rot'].append(gt_rotation)\n",
    "            \n",
    "            preds = poses_est[0][i][1].data.cpu().numpy()\n",
    "            \n",
    "            pr_copy = np.copy(preds)\n",
    "            \n",
    "            preds[3] = pr_copy[6] # swap 3 & 6, we used W last; want W first in quat\n",
    "            preds[6] = pr_copy[3]\n",
    "            preds[:3] = preds[:3] * DEPTH_SCALE \n",
    "            \n",
    "            predictions['camera']['preds']['tran'].append(preds[:3])\n",
    "            predictions['camera']['preds']['rot'].append(preds[3:])\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m camera_metrics \u001b[38;5;241m=\u001b[39m \u001b[43meval_camera\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m, in \u001b[0;36meval_camera\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m      7\u001b[0m pred_tran \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtran\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m pred_rot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m gt_tran \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcamera\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtran\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m gt_rot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(predictions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     13\u001b[0m top1_error \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtran\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(gt_tran \u001b[38;5;241m-\u001b[39m pred_tran, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrot\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mmultiply(pred_rot, gt_rot), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m180\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpi,\n\u001b[1;32m     16\u001b[0m }\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/numpy/core/shape_base.py:293\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overrides\u001b[39m.\u001b[39mARRAY_FUNCTION_ENABLED:\n\u001b[1;32m    291\u001b[0m     \u001b[39m# raise warning if necessary\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     _arrays_for_stack_dispatcher(tup, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m arrs \u001b[39m=\u001b[39m atleast_2d(\u001b[39m*\u001b[39;49mtup)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/numpy/core/shape_base.py:121\u001b[0m, in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    119\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[0;32m--> 121\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[1;32m    122\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    123\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuti/lib/python3.9/site-packages/torch/tensor.py:621\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "camera_metrics = eval_camera(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in camera_metrics:\n",
    "    print(k, camera_metrics[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('cuti')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "167ed4d760c5bbb8b58639929312eda6fcad32a00c0382e2adffde024859406a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
