{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"C:/Users/User/source/CuTi/matterport/rgb/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"matterport/mp3d_planercnn_json/cached_set_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(osp.join(path)) as f:\n",
    "   split = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(split['data'][0]['0']['file_name']).split('/')[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = os.path.join(root,'/'.join(str(split['data'][0]['0']['file_name']).split('/')[6:]))\n",
    "img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(len(split['data'])):\n",
    "    \n",
    "    for imgnum in ['0', '1']:\n",
    "        img_name = os.path.join(root, '/'.join(str(split['data'][i][imgnum]['file_name']).split('/')[6:]))\n",
    "        images.append(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['data'][0]['rel_pose']['position']+split['data'][i]['rel_pose']['rotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_info = {'images': [], 'poses': [], 'intrinsics': []}\n",
    "base_pose = np.array([0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(split['data'])):\n",
    "    images = []\n",
    "    for imgnum in ['0', '1']:\n",
    "        img_name = os.path.join(root, '/'.join(str(split['data'][i][imgnum]['file_name']).split('/')[6:]))\n",
    "        images.append(img_name)\n",
    "    \n",
    "    rel_pose = np.array(split['data'][i]['rel_pose']['position'] + split['data'][i]['rel_pose']['rotation'])\n",
    "    og_rel_pose = np.copy(rel_pose)\n",
    "\n",
    "    # on matterport, we scale depths to balance rot & trans loss\n",
    "    rel_pose[:3] /= 5.0\n",
    "    cprp = np.copy(rel_pose)\n",
    "    rel_pose[6] = cprp[3] # swap 3 & 6, we want W last for consistency with our other datasets\n",
    "    rel_pose[3] = cprp[6]\n",
    "    if rel_pose[6] < 0: # normalize quaternions to have positive \"W\"\n",
    "        rel_pose[3:] *= -1\n",
    "    poses = np.vstack([base_pose, rel_pose])\n",
    "\n",
    "    intrinsics = np.array([[517.97, 517.97, 320, 240], [517.97, 517.97, 320, 240]]) # 480 x 640 imgs\n",
    "\n",
    "    scene_info['images'].append(images)\n",
    "    scene_info['poses'] += [poses]\n",
    "    scene_info['intrinsics'] += [intrinsics]\n",
    "\n",
    "    print(scene_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = [\"matterport/rgb/rgb/1LXtFkjw3qL/0_2_0.png\",\"matterport/rgb/rgb/1LXtFkjw3qL/0_2_1.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    images.append(cv2.imread(images_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 71, 107,  95],\n",
       "         [ 72, 108,  96],\n",
       "         [ 71, 110,  95],\n",
       "         ...,\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134]],\n",
       " \n",
       "        [[ 71, 107,  96],\n",
       "         [ 72, 108,  96],\n",
       "         [ 72, 108,  96],\n",
       "         ...,\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134]],\n",
       " \n",
       "        [[ 72, 105,  97],\n",
       "         [ 71, 106,  95],\n",
       "         [ 71, 105,  95],\n",
       "         ...,\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134],\n",
       "         [143, 139, 134]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[157, 174, 161],\n",
       "         [155, 172, 159],\n",
       "         [152, 167, 153],\n",
       "         ...,\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147]],\n",
       " \n",
       "        [[159, 173, 161],\n",
       "         [164, 178, 165],\n",
       "         [159, 173, 160],\n",
       "         ...,\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147]],\n",
       " \n",
       "        [[162, 176, 164],\n",
       "         [184, 197, 183],\n",
       "         [138, 150, 152],\n",
       "         ...,\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147],\n",
       "         [153, 153, 147]]], dtype=uint8),\n",
       " array([[[121, 138, 144],\n",
       "         [121, 138, 144],\n",
       "         [121, 138, 144],\n",
       "         ...,\n",
       "         [149, 153, 158],\n",
       "         [149, 153, 158],\n",
       "         [148, 152, 157]],\n",
       " \n",
       "        [[121, 138, 144],\n",
       "         [121, 138, 145],\n",
       "         [121, 138, 145],\n",
       "         ...,\n",
       "         [147, 153, 158],\n",
       "         [148, 154, 159],\n",
       "         [148, 152, 157]],\n",
       " \n",
       "        [[120, 137, 146],\n",
       "         [120, 138, 146],\n",
       "         [121, 138, 146],\n",
       "         ...,\n",
       "         [147, 153, 158],\n",
       "         [148, 154, 159],\n",
       "         [148, 152, 157]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[126, 152, 170],\n",
       "         [119, 147, 162],\n",
       "         [118, 146, 160],\n",
       "         ...,\n",
       "         [138, 165, 185],\n",
       "         [138, 165, 185],\n",
       "         [139, 166, 186]],\n",
       " \n",
       "        [[117, 145, 161],\n",
       "         [116, 142, 162],\n",
       "         [116, 140, 166],\n",
       "         ...,\n",
       "         [138, 165, 185],\n",
       "         [139, 165, 186],\n",
       "         [140, 167, 187]],\n",
       " \n",
       "        [[112, 135, 164],\n",
       "         [112, 135, 164],\n",
       "         [115, 122, 162],\n",
       "         ...,\n",
       "         [138, 165, 185],\n",
       "         [138, 165, 185],\n",
       "         [140, 167, 187]]], dtype=uint8)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(images).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 71., 107.,  95.],\n",
       "         [ 72., 108.,  96.],\n",
       "         [ 71., 110.,  95.],\n",
       "         ...,\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.]],\n",
       "\n",
       "        [[ 71., 107.,  96.],\n",
       "         [ 72., 108.,  96.],\n",
       "         [ 72., 108.,  96.],\n",
       "         ...,\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.]],\n",
       "\n",
       "        [[ 72., 105.,  97.],\n",
       "         [ 71., 106.,  95.],\n",
       "         [ 71., 105.,  95.],\n",
       "         ...,\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.],\n",
       "         [143., 139., 134.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[157., 174., 161.],\n",
       "         [155., 172., 159.],\n",
       "         [152., 167., 153.],\n",
       "         ...,\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.]],\n",
       "\n",
       "        [[159., 173., 161.],\n",
       "         [164., 178., 165.],\n",
       "         [159., 173., 160.],\n",
       "         ...,\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.]],\n",
       "\n",
       "        [[162., 176., 164.],\n",
       "         [184., 197., 183.],\n",
       "         [138., 150., 152.],\n",
       "         ...,\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.],\n",
       "         [153., 153., 147.]]],\n",
       "\n",
       "\n",
       "       [[[121., 138., 144.],\n",
       "         [121., 138., 144.],\n",
       "         [121., 138., 144.],\n",
       "         ...,\n",
       "         [149., 153., 158.],\n",
       "         [149., 153., 158.],\n",
       "         [148., 152., 157.]],\n",
       "\n",
       "        [[121., 138., 144.],\n",
       "         [121., 138., 145.],\n",
       "         [121., 138., 145.],\n",
       "         ...,\n",
       "         [147., 153., 158.],\n",
       "         [148., 154., 159.],\n",
       "         [148., 152., 157.]],\n",
       "\n",
       "        [[120., 137., 146.],\n",
       "         [120., 138., 146.],\n",
       "         [121., 138., 146.],\n",
       "         ...,\n",
       "         [147., 153., 158.],\n",
       "         [148., 154., 159.],\n",
       "         [148., 152., 157.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[126., 152., 170.],\n",
       "         [119., 147., 162.],\n",
       "         [118., 146., 160.],\n",
       "         ...,\n",
       "         [138., 165., 185.],\n",
       "         [138., 165., 185.],\n",
       "         [139., 166., 186.]],\n",
       "\n",
       "        [[117., 145., 161.],\n",
       "         [116., 142., 162.],\n",
       "         [116., 140., 166.],\n",
       "         ...,\n",
       "         [138., 165., 185.],\n",
       "         [139., 165., 186.],\n",
       "         [140., 167., 187.]],\n",
       "\n",
       "        [[112., 135., 164.],\n",
       "         [112., 135., 164.],\n",
       "         [115., 122., 162.],\n",
       "         ...,\n",
       "         [138., 165., 185.],\n",
       "         [138., 165., 185.],\n",
       "         [140., 167., 187.]]]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.from_numpy(images).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 480, 640, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 480, 640])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "def color_transform( images):\n",
    "    \"\"\"color jittering\"\"\"\n",
    "    num, ch, ht, wd = images.shape\n",
    "    images = images.permute(1, 2, 3, 0).reshape(ch, ht, wd * num)\n",
    "    images = 255 * augcolor(images[[2, 1, 0]] / 255.0)\n",
    "    return (\n",
    "        images[[2, 1, 0]].reshape(ch, ht, wd, num).permute(3, 0, 1, 2).contiguous()\n",
    "    )\n",
    "\n",
    "augcolor = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.25, contrast=0.25, saturation=0.25, hue=0.4 / 3.14\n",
    "                ),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = color_transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 57.,  59.,  56.,  ..., 165., 165., 165.],\n",
       "          [ 57.,  59.,  59.,  ..., 165., 165., 165.],\n",
       "          [ 59.,  57.,  57.,  ..., 165., 165., 165.],\n",
       "          ...,\n",
       "          [180., 176., 175.,  ..., 177., 177., 177.],\n",
       "          [183., 189., 184.,  ..., 177., 177., 177.],\n",
       "          [187., 219., 153.,  ..., 177., 177., 177.]],\n",
       "\n",
       "         [[116., 117., 120.,  ..., 157., 157., 157.],\n",
       "          [116., 117., 117.,  ..., 157., 157., 157.],\n",
       "          [114., 115., 114.,  ..., 157., 157., 157.],\n",
       "          ...,\n",
       "          [207., 205., 198.,  ..., 176., 176., 176.],\n",
       "          [206., 213., 206.,  ..., 176., 176., 176.],\n",
       "          [211., 240., 176.,  ..., 176., 176., 176.]],\n",
       "\n",
       "         [[ 92.,  93.,  91.,  ..., 150., 150., 150.],\n",
       "          [ 93.,  93.,  93.,  ..., 150., 150., 150.],\n",
       "          [ 95.,  92.,  92.,  ..., 150., 150., 150.],\n",
       "          ...,\n",
       "          [183., 181., 175.,  ..., 168., 168., 168.],\n",
       "          [184., 189., 183.,  ..., 168., 168., 168.],\n",
       "          [188., 217., 176.,  ..., 168., 168., 168.]]],\n",
       "\n",
       "\n",
       "        [[[128., 128., 128.,  ..., 169., 169., 168.],\n",
       "          [128., 128., 128.,  ..., 166., 168., 168.],\n",
       "          [127., 127., 129.,  ..., 166., 168., 168.],\n",
       "          ...,\n",
       "          [134., 123., 122.,  ..., 147., 147., 149.],\n",
       "          [119., 119., 120.,  ..., 147., 151., 151.],\n",
       "          [114., 114., 121.,  ..., 147., 147., 151.]],\n",
       "\n",
       "         [[159., 159., 159.,  ..., 177., 177., 176.],\n",
       "          [159., 159., 159.,  ..., 177., 178., 176.],\n",
       "          [158., 160., 160.,  ..., 177., 178., 176.],\n",
       "          ...,\n",
       "          [181., 174., 172.,  ..., 199., 199., 200.],\n",
       "          [172., 166., 164.,  ..., 199., 199., 201.],\n",
       "          [157., 157., 137.,  ..., 199., 199., 201.]],\n",
       "\n",
       "         [[166., 166., 166.,  ..., 184., 184., 183.],\n",
       "          [166., 168., 168.,  ..., 184., 186., 183.],\n",
       "          [169., 169., 169.,  ..., 184., 186., 183.],\n",
       "          ...,\n",
       "          [205., 193., 189.,  ..., 225., 225., 226.],\n",
       "          [192., 194., 201.,  ..., 225., 226., 228.],\n",
       "          [198., 198., 196.,  ..., 225., 225., 228.]]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 480, 640])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizey,sizex = [384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalex = sizex / images.shape[-1]\n",
    "scalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaley = sizey / images.shape[-2]\n",
    "scaley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(6,6,128,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(6,6,128,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6, 128, 8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
